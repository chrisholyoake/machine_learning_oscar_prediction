{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import pandas as pd\n",
    "import requests\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "File b'Movies.csv' does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-bc7821978287>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m#Create DF with CSV Files\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mDF\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCSV1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mDF2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCSV2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skipfooter, doublequote, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    676\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 678\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    679\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    680\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    438\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    439\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 440\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    441\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    785\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    786\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 787\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    788\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    789\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1012\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'c'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1013\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'c'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1014\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1015\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1016\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'python'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1706\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'usecols'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1707\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1708\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1709\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1710\u001b[0m         \u001b[0mpassed_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnames\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: File b'Movies.csv' does not exist"
     ]
    }
   ],
   "source": [
    "#Created seperate CSVs with movie lists due to API limitations\n",
    "CSV1 = 'Movies.csv'\n",
    "CSV2 = 'Movies2.csv'\n",
    "\n",
    "#URL for API with API Key\n",
    "url2 = \"http://www.omdbapi.com/?apikey=trilogy&t=\"\n",
    "\n",
    "#Create DF with CSV Files\n",
    "DF = pd.read_csv(CSV1)\n",
    "DF2 = pd.read_csv(CSV2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pull only the titles from the CSVs and create a list\n",
    "titles = DF[\"Title\"].values.tolist()\n",
    "titles2 = DF2[\"Title\"].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#create an empty list for the responses\n",
    "responses = [];\n",
    "\n",
    "#loop through the api and pull the data for each of the movies from the CSV, we have a pause added \n",
    "for i in range(0, len(titles)):\n",
    "    movie_data = requests.get(url2 + titles[i]).json()\n",
    "    responses.append(movie_data)\n",
    "    if i % 500 == 0:\n",
    "        print(\"Collected \" + str(i) + \" movies.\")\n",
    "        time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create an empty list for the second round of responses for csv number 2\n",
    "responses2 = [];\n",
    "\n",
    "#loop through the api and pull data for reach of the movies for the second csv, we have a pause added\n",
    "for i in range(0, len(titles2)):\n",
    "    movie_data = requests.get(url2 + titles2[i]).json()\n",
    "    responses2.append(movie_data)\n",
    "    if i % 500 == 0:\n",
    "        print(\"Collected \" + str(i) + \" movies.\")\n",
    "        time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "responses2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#empty lists for the data \n",
    "Title = []\n",
    "Year = []\n",
    "Rated = []\n",
    "Released = []\n",
    "Runtime = []\n",
    "Genre = []\n",
    "Director = []\n",
    "Writer = []\n",
    "Actors = []\n",
    "Plot = []\n",
    "Language = []\n",
    "Country = []\n",
    "Poster = []\n",
    "IMDB = []\n",
    "RottenTomatoes = []\n",
    "Metacritic = []\n",
    "BoxOffice = []\n",
    "Type = []\n",
    "Production = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pulls data from the json file (response) and adds the data into the empty lists \n",
    "for data in responses:\n",
    "   if data[\"Response\"] == \"True\":\n",
    "        try:\n",
    "            Title.append(data[\"Title\"])\n",
    "        except:\n",
    "            Title.append('N/A')\n",
    "        try:        \n",
    "            Year.append(data[\"Year\"])\n",
    "        except:\n",
    "            Year.append('N/A')\n",
    "        try:        \n",
    "            Rated.append(data[\"Rated\"])\n",
    "        except:\n",
    "            Rated.append('N/A')        \n",
    "        try:        \n",
    "            Released.append(data[\"Released\"])\n",
    "        except:\n",
    "            Released.append('N/A')     \n",
    "        try:        \n",
    "            Runtime.append(data[\"Runtime\"])\n",
    "        except:\n",
    "            Runtime.append('N/A')   \n",
    "        try:\n",
    "            Genre.append(data[\"Genre\"])\n",
    "        except:\n",
    "            Genre.append('N/A')\n",
    "        try:\n",
    "            Director.append(data[\"Director\"])\n",
    "        except:\n",
    "            Director.append('N/A')\n",
    "        try:\n",
    "            Writer.append(data[\"Writer\"])\n",
    "        except:\n",
    "            Writer.append('N/A')   \n",
    "        try:\n",
    "            Actors.append(data[\"Actors\"])\n",
    "        except:\n",
    "            Actors.append('N/A')\n",
    "        try:\n",
    "            Language.append(data[\"Language\"])\n",
    "        except:\n",
    "            Language.append('N/A')            \n",
    "        try:\n",
    "            Country.append(data[\"Country\"])\n",
    "        except:\n",
    "            Country.append('N/A')\n",
    "        try:\n",
    "            IMDB.append(data[\"Ratings\"][0][\"Value\"])\n",
    "        except:\n",
    "            IMDB.append('N/A')\n",
    "        try:\n",
    "            RottenTomatoes.append(data[\"Ratings\"][1][\"Value\"])\n",
    "        except:\n",
    "            RottenTomatoes.append('N/A')\n",
    "        try:\n",
    "            Metacritic.append(data[\"Ratings\"][2][\"Value\"])\n",
    "        except:\n",
    "            Metacritic.append('N/A')\n",
    "        try:\n",
    "            Type.append(data[\"Type\"])\n",
    "        except:\n",
    "            Type.append('N/A')\n",
    "        try:\n",
    "            BoxOffice.append(data[\"BoxOffice\"])\n",
    "        except:\n",
    "            BoxOffice.append('N/A')\n",
    "        try:\n",
    "            Production.append(data[\"Production\"])\n",
    "        except:\n",
    "            Production.append('N/A')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pulls data from the json file (response2) and adds the data into the empty lists \n",
    "\n",
    "for data in responses2:\n",
    "   if data[\"Response\"] == \"True\":\n",
    "        try:\n",
    "            Title.append(data[\"Title\"])\n",
    "        except:\n",
    "            Title.append('N/A')\n",
    "        try:        \n",
    "            Year.append(data[\"Year\"])\n",
    "        except:\n",
    "            Year.append('N/A')\n",
    "        try:        \n",
    "            Rated.append(data[\"Rated\"])\n",
    "        except:\n",
    "            Rated.append('N/A')        \n",
    "        try:        \n",
    "            Released.append(data[\"Released\"])\n",
    "        except:\n",
    "            Released.append('N/A')     \n",
    "        try:        \n",
    "            Runtime.append(data[\"Runtime\"])\n",
    "        except:\n",
    "            Runtime.append('N/A')   \n",
    "        try:\n",
    "            Genre.append(data[\"Genre\"])\n",
    "        except:\n",
    "            Genre.append('N/A')\n",
    "        try:\n",
    "            Director.append(data[\"Director\"])\n",
    "        except:\n",
    "            Director.append('N/A')\n",
    "        try:\n",
    "            Writer.append(data[\"Writer\"])\n",
    "        except:\n",
    "            Writer.append('N/A')   \n",
    "        try:\n",
    "            Actors.append(data[\"Actors\"])\n",
    "        except:\n",
    "            Actors.append('N/A')\n",
    "        try:\n",
    "            Language.append(data[\"Language\"])\n",
    "        except:\n",
    "            Language.append('N/A')            \n",
    "        try:\n",
    "            Country.append(data[\"Country\"])\n",
    "        except:\n",
    "            Country.append('N/A')\n",
    "        try:\n",
    "            IMDB.append(data[\"Ratings\"][0][\"Value\"])\n",
    "        except:\n",
    "            IMDB.append('N/A')\n",
    "        try:\n",
    "            RottenTomatoes.append(data[\"Ratings\"][1][\"Value\"])\n",
    "        except:\n",
    "            RottenTomatoes.append('N/A')\n",
    "        try:\n",
    "            Metacritic.append(data[\"Ratings\"][2][\"Value\"])\n",
    "        except:\n",
    "            Metacritic.append('N/A')\n",
    "        try:\n",
    "            Type.append(data[\"Type\"])\n",
    "        except:\n",
    "            Type.append('N/A')\n",
    "        try:\n",
    "            BoxOffice.append(data[\"BoxOffice\"])\n",
    "        except:\n",
    "            BoxOffice.append('N/A')\n",
    "        try:\n",
    "            Production.append(data[\"Production\"])\n",
    "        except:\n",
    "            Production.append('N/A')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creates DF with the lists\n",
    "Movie1DF = pd.DataFrame({\"Title\": Title,\n",
    "                         \"Year\": Year,\n",
    "                         \"Rated\": Rated,\n",
    "                         \"Released\": Released,\n",
    "                         \"Runtime\": Runtime,\n",
    "                         \"Genre\": Genre,\n",
    "                         \"Director\": Director,\n",
    "                         \"Writer\": Writer,\n",
    "                         \"Actors\": Actors,\n",
    "                         \"Language\": Language,\n",
    "                         \"Country\": Country,\n",
    "                         \"IMDB\": IMDB,\n",
    "                         \"Rotten Tomatoes\": RottenTomatoes,\n",
    "                         \"Metacritic\": Metacritic,\n",
    "                         \"Box Office\": BoxOffice,\n",
    "                         \"Type\": Type,\n",
    "                         \"Production\": Production\n",
    "                        })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creates DF with the lists\n",
    "Movie2DF = pd.DataFrame({\"Title\": Title,\n",
    "                         \"Year\": Year,\n",
    "                         \"Rated\": Rated,\n",
    "                         \"Released\": Released,\n",
    "                         \"Runtime\": Runtime,\n",
    "                         \"Genre\": Genre,\n",
    "                         \"Director\": Director,\n",
    "                         \"Writer\": Writer,\n",
    "                         \"Actors\": Actors,\n",
    "                         \"Language\": Language,\n",
    "                         \"Country\": Country,\n",
    "                         \"IMDB\": IMDB,\n",
    "                         \"Rotten Tomatoes\": RottenTomatoes,\n",
    "                         \"Metacritic\": Metacritic,\n",
    "                         \"Box Office\": BoxOffice,\n",
    "                         \"Type\": Type,\n",
    "                         \"Production\": Production\n",
    "                        })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Combines the two lists into 1\n",
    "movie_2000 = [Movie1DF,Movie2DF]\n",
    "combined_movies = pd.concat(movie_2000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
